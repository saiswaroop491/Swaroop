{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fed7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7bdec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\SAI\\MNK_Techfocus\\archive\\train',\n",
    "    target_size=(64,64),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4d769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\SAI\\MNK_Techfocus\\archive\\test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49212090",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46483a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=64 , kernel_size=3 , activation='relu' , input_shape=[64,64,3]))\n",
    "cnn.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6d1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=64 , kernel_size=3 , activation='relu' ))\n",
    "cnn.add(MaxPool2D(pool_size=2 , strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26f9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a2f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728320e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fbf227",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f6b88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b8ab47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 7s 360ms/step - loss: 0.9456 - accuracy: 0.4901 - val_loss: 0.7069 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 6s 318ms/step - loss: 0.7000 - accuracy: 0.5404 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 6s 312ms/step - loss: 0.6934 - accuracy: 0.5476 - val_loss: 0.7781 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 6s 317ms/step - loss: 0.7047 - accuracy: 0.5458 - val_loss: 0.6888 - val_accuracy: 0.5929\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 6s 334ms/step - loss: 0.6961 - accuracy: 0.5889 - val_loss: 0.6995 - val_accuracy: 0.5143\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 6s 314ms/step - loss: 0.6782 - accuracy: 0.5673 - val_loss: 0.6921 - val_accuracy: 0.5357\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 6s 307ms/step - loss: 0.7189 - accuracy: 0.5853 - val_loss: 0.6886 - val_accuracy: 0.5357\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 6s 317ms/step - loss: 0.6566 - accuracy: 0.6050 - val_loss: 0.6778 - val_accuracy: 0.6143\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 6s 313ms/step - loss: 0.6463 - accuracy: 0.6445 - val_loss: 1.0346 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 6s 307ms/step - loss: 0.6629 - accuracy: 0.6212 - val_loss: 0.6782 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e1ea55730>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set,validation_data=test_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7eeaf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 6s 336ms/step - loss: 0.3204 - accuracy: 0.8492 - val_loss: 0.8083 - val_accuracy: 0.6643\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 6s 312ms/step - loss: 0.3257 - accuracy: 0.8600 - val_loss: 0.7795 - val_accuracy: 0.6786\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 6s 305ms/step - loss: 0.4723 - accuracy: 0.8079 - val_loss: 0.7072 - val_accuracy: 0.7000\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 5s 315ms/step - loss: 0.2884 - accuracy: 0.8725 - val_loss: 0.8024 - val_accuracy: 0.6643\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 6s 343ms/step - loss: 0.3168 - accuracy: 0.8564 - val_loss: 0.8353 - val_accuracy: 0.6857\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 6s 338ms/step - loss: 0.3348 - accuracy: 0.8510 - val_loss: 0.7513 - val_accuracy: 0.6857\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 6s 348ms/step - loss: 0.3026 - accuracy: 0.8671 - val_loss: 0.8360 - val_accuracy: 0.6429\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 6s 340ms/step - loss: 0.2624 - accuracy: 0.8815 - val_loss: 0.7930 - val_accuracy: 0.6643\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 6s 326ms/step - loss: 0.2385 - accuracy: 0.8977 - val_loss: 0.8447 - val_accuracy: 0.6929\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 6s 308ms/step - loss: 0.2579 - accuracy: 0.8923 - val_loss: 0.9621 - val_accuracy: 0.6929\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(x=training_set,validation_data=test_set,epochs=10)\n",
    "\n",
    "cnn.save(r'C:\\Users\\SAI\\MNK_Techfocus\\dog_cat_recog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "559f5081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = tf.keras.utils.load_img(r'C:\\Users\\SAI\\Downloads\\cat3.jpg',target_size=(64,64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31418b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "967a8904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][1]==1:\n",
    "    print(\"Dog\")\n",
    "else:\n",
    "    print(\"Cat\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2d76157",
   "metadata": {},
   "source": [
    "[[0.48332196 0.51667804]]      #dog"
   ]
  },
  {
   "cell_type": "raw",
   "id": "faef91e4",
   "metadata": {},
   "source": [
    "[[0.48270428 0.5172957 ]]      #cat\n",
    "[[0.48933145 0.5106685 ]]\n",
    "[[0.45721078 0.5427892 ]]\n",
    "[[0.48324218 0.5167578 ]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnk_learning",
   "language": "python",
   "name": "mnk_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
